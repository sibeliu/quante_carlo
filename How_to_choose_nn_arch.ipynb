{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96776a9-0fdb-4d11-9d77-39c03c1c5644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import quante\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF, Matern\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e717911-c4ee-4c29-8187-88a52aacd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "pd.DataFrame(iris.data).to_csv('X.csv', index=False)\n",
    "with open('y.csv', 'w') as f:\n",
    "    f.write(','.join([str(x) for x in iris.target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38de09-d4a5-4e62-b21e-1b87909244d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def instance(arch):\n",
    "    \n",
    "        X = pd.read_csv('X.csv')\n",
    "        with open('y.csv') as f:\n",
    "            y = f.read().split(',')\n",
    "            \n",
    "        clf = MLPClassifier(solver='sgd', max_iter=500,\n",
    "                        hidden_layer_sizes=arch[:3], alpha=arch[3], random_state=1)\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            cvs = cross_val_score(clf, X, y)\n",
    "        return cvs\n",
    "        \n",
    "#    print(\"Call a single instance of MLP Classifier\") \n",
    "#    print(instance((3,3)))\n",
    "    \n",
    "    hp_tune = quante.carlo(instance, [[2, 16], [2, 4], [2, 16], [.01, .99]], kernel=DotProduct()+ WhiteKernel(), n_batches=100, n_processors=4, n_iterations=5)\n",
    "    \n",
    "    p = mp.Pool()\n",
    "    start = time.time()\n",
    "    \n",
    "    session, iterations = hp_tune(p)\n",
    "    print(\"{} seconds\".format(round(time.time() - start,2)))\n",
    "    p.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe709758-2937-4306-879a-7c3cedd64b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = session.summary()\n",
    "summary['iteration_id'] = iterations\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9e244-30f9-4cef-89be-577266fda4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = summary[['score', 'iteration_id']].groupby('iteration_id').mean().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9069a02-61b9-47f1-aec6-b4afd418e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_alpha=  [x[:3]+(round(x[3],3),) for x in summary['layers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a462130-9b81-44c1-afef-d92f86a7ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize =(13, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.boxplot(session.score_history)\n",
    "ax.set_xticklabels(rounded_alpha)\n",
    "plt.xticks(rotation=60)\n",
    "bx = plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96158d44-10ef-4ad9-b714-82e2e81e5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def instance(hp_parameter):\n",
    "    \n",
    "        X = pd.read_csv('X.csv')\n",
    "        with open('y.csv') as f:\n",
    "            y = f.read().split(',')\n",
    "            \n",
    "        clf = LogisticRegression(solver='saga', penalty = 'elasticnet', l1_ratio=hp_parameter[0], max_iter=200 )\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            cvs = cross_val_score(clf, X, y)\n",
    "        \n",
    "        return cvs\n",
    "        \n",
    "    \n",
    "    hp_tune = quante.carlo(instance, [[.05, .95]], kernel=DotProduct()+ WhiteKernel(), n_batches=7, n_processors=4, n_iterations=5)\n",
    "    p = mp.Pool()\n",
    "    start = time.time()\n",
    "    \n",
    "    session, iterations = hp_tune(p)\n",
    "    print(\"{} seconds\".format(round(time.time() - start,2)))\n",
    "    p.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57754c4a-c8cb-4080-8325-37980fb9bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def instance(hp_parameter):\n",
    "    \n",
    "        X = pd.read_csv('X.csv')\n",
    "        with open('y.csv') as f:\n",
    "            y = f.read().split(',')\n",
    "            \n",
    "        clf = LogisticRegression(solver='saga', penalty = 'elasticnet', l1_ratio=hp_parameter[0], max_iter=200 )\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            cvs = cross_val_score(clf, X, y)\n",
    "        \n",
    "        return cvs\n",
    "        \n",
    "    \n",
    "    hp_tune = quante.carlo(instance, [[.05, .95]], kernel=DotProduct()+ WhiteKernel(), n_batches=7, n_processors=4, n_iterations=5)\n",
    "    p = mp.Pool()\n",
    "    start = time.time()\n",
    "    \n",
    "    session, iterations = hp_tune(p)\n",
    "    print(\"{} seconds\".format(round(time.time() - start,2)))\n",
    "    p.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da219579-29af-4a8e-b5fc-08a88734caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = session.summary()\n",
    "summary['iteration_id'] = iterations\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af5140-d021-45ca-9d46-646604c49660",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = summary[['score', 'iteration_id']].groupby('iteration_id').mean().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63a41f5-4080-4289-990b-220f682cacff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f574469-de7b-4e84-a1fa-11b201b98809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce41f27e-56e2-43cc-8670-034bebf98367",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNeuralNetwork\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs=None, arch=None, n_outputs=None):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        if n_inputs and arch and n_outputs:\n",
    "            self.make_arch(n_inputs, arch, n_outputs)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.stack(x)\n",
    "        return logits\n",
    "\n",
    "    def make_arch(self, n_inputs, arch, n_outputs, inner_function='Relu', last_function = None):\n",
    "        layers = [torch.nn.Linear(n_inputs, arch[0])]\n",
    "        for a in range(len(arch)-1):\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            layers.append(torch.nn.Linear(arch[a], arch[a+1]))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(arch[-1], n_outputs))\n",
    "    #    layers.append(torch.nn.Softmax(dim=1))                    # works better without this\n",
    "\n",
    "        self.stack = torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7a178f-7709-4679-b837-9ebf7e4f8f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class data_loader:\n",
    "    def __init__(self,batch_pct):\n",
    "        self.X_train = pd.read_csv('X_train.csv')\n",
    "        self.X_test = pd.read_csv('X_test.csv')\n",
    "        self.y_train = pd.read_csv('y_train.csv')\n",
    "        self.y_test = pd.read_csv('y_test.csv')\n",
    "        # with open('y_train.csv') as f:\n",
    "        #     self.y_train = [float(x) for x in f.read().split(',')]\n",
    "        # with open('y_test.csv') as f:\n",
    "        #     self.y_test = [float(x) for x in f.read().split(',')]\n",
    "\n",
    "        self.train_batch_size = int(np.floor(self.X_train.shape[0] * batch_pct))\n",
    "        self.test_batch_size = int(np.floor(self.X_test.shape[0] * batch_pct))\n",
    "        self.batch_pct = batch_pct\n",
    "        \n",
    "    def get_batch(self,batch):\n",
    "        if batch < 0:\n",
    "            return self.X_test, self.y_test\n",
    "        else:\n",
    "            return self.X_train[(batch*self.train_batch_size):((batch+1)*self.train_batch_size)],\\\n",
    "                   self.y_train[(batch*self.train_batch_size):((batch+1)*self.train_batch_size)]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b177b3d5-ddfb-435a-9dc7-0063178f8547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443de3fb-c36e-42db-aee4-26bc77fa37e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    train_batch_size = 100\n",
    "    n_batches = 4\n",
    "    n_iterations = 5\n",
    "    input_layer_size = 28*28\n",
    "    output_layer_size = 10\n",
    "\n",
    "    def instance(p):\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        device = 'cuda:'+str(p['thread_id'])\n",
    "        model = NeuralNetwork(input_layer_size, p['next_points'], n_outputs=output_layer_size)\n",
    "        model.to(device)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "        loss_history = []\n",
    "        model.train()\n",
    "\n",
    "        loader = data_loader(.05)\n",
    "    \n",
    "        for i in range(n_iterations):\n",
    "            for batch in range(n_batches):\n",
    "                X_train, y_train = loader.get_batch(batch)\n",
    "\n",
    "                X_train_torch = torch.tensor(X_train.values, dtype=torch.float)\n",
    "                y_train_torch = torch.tensor(y_train.values, dtype=torch.float)\n",
    "\n",
    "                X = X_train_torch.to(device)\n",
    "                y = y_train_torch.to(device)\n",
    "\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                loss_history.append(loss.item())\n",
    "\n",
    "        X_test, y_test = loader.get_batch(-1)\n",
    "\n",
    "        model.eval()\n",
    "        X_test_torch = torch.tensor(X_test.values, dtype=torch.float)\n",
    "        y_test_torch = torch.tensor(y_test.values, dtype=torch.float)\n",
    "\n",
    "        X = X_test_torch.to(device)\n",
    "        y = y_test_torch.to(device)\n",
    "        pred = model(X)\n",
    "\n",
    "\n",
    "        return loss.item()#loss.item()#.detatch()\n",
    "    \n",
    "    def wrapper(x):\n",
    "        return instance(x)\n",
    "    #k = instance({'next_points': (17, 13), 'thread_id': 1})\n",
    "    hp_tune = quante.carlo(worker.instance, [[64, 128], [64, 128], [64, 128]], kernel=DotProduct()+ WhiteKernel(), \n",
    "                            n_batches=7, n_processors=4, n_iterations=5, keep_thread_id=True)\n",
    "    p = mp.Pool(processes = 4)\n",
    "    \n",
    "#     start = time.time()\n",
    "    \n",
    "# #    session, iterations = hp_tune(p)\n",
    "    session = hp_tune(p)\n",
    "#     print(\"{} seconds\".format(round(time.time() - start,2)))\n",
    "#     p.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "227b4c91-7dbf-4b17-ab68-c1e3def7f173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(126, 68, 103), (91, 107, 102), (82, 126, 106), (75, 100, 108)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.layer_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a8f7fb4-671e-4b0b-bbdd-bb8ed7b1124a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '9\\n0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m x,y\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mget_batch(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mdata_loader.__init__\u001b[0;34m(self, batch_pct)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '9\\n0'"
     ]
    }
   ],
   "source": [
    "df = data_loader(.05)\n",
    "x,y=df.get_batch(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cc2bbf1-0dba-426e-b4bd-11cbda8c3c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_35264/2551649576.py\", line 11, in instance\n    loss_fn = torch.nn.CrossEntropyLoss()\nNameError: name 'torch' is not defined. Did you mean: 'arch'?\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#    session, iterations = hp_tune(p)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mhp_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start,\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m     67\u001b[0m     results \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mmap(instance, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[0;32m~/SageMaker/projects/quante_carlo/quante.py:98\u001b[0m, in \u001b[0;36mcarlo.<locals>.qc_tune_nn\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqc_tune_nn\u001b[39m(p):\n\u001b[1;32m     97\u001b[0m         q \u001b[38;5;241m=\u001b[39m hp_tuning_session(f, limits, kernel, n_batches, n_processors)\n\u001b[0;32m---> 98\u001b[0m         \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_gpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_thread_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m         iteration_id \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m n_processors\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m#        for j in range(n_iterations):\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m#            q.get_new_points()\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#            q.test_new_points(p, keep_thread_id)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#            iteration_id += [j+1]*n_processors\u001b[39;00m\n",
      "File \u001b[0;32m~/SageMaker/projects/quante_carlo/quante.py:28\u001b[0m, in \u001b[0;36mhp_tuning_session.initialize_gpr\u001b[0;34m(self, p, keep_thread_id)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_random_points(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_processors)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_points\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_new_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_thread_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SageMaker/projects/quante_carlo/quante.py:68\u001b[0m, in \u001b[0;36mhp_tuning_session.test_new_points\u001b[0;34m(self, p, pass_thread_id)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_new_points\u001b[39m(\u001b[38;5;28mself\u001b[39m, p, pass_thread_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pass_thread_id:\n\u001b[0;32m---> 68\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnext_points\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_points\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                                                              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_processors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_points)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    train_batch_size = 1000\n",
    "    n_batches = 4\n",
    "    n_iterations = 10\n",
    "    input_layer_size = 28*28\n",
    "    output_layer_size = 10\n",
    "    \n",
    "    def instance(arch):\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        device = 'cuda:'+str(arch)\n",
    "        model = NeuralNetwork(input_layer_size, (64, 64), output_layer_size)\n",
    "        model.to(device)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "        loss_history = []\n",
    "        model.train()\n",
    "\n",
    "        loader = data_loader(.05)\n",
    "        batch = 1\n",
    "        X_train, y_train = loader.get_batch(batch)\n",
    "\n",
    "        #X_train_torch = torch.tensor(X_train.values, dtype=torch.float)\n",
    "        #y_train_torch = torch.tensor(y_train, dtype=torch.float)\n",
    "#         for i in range(n_iterations):\n",
    "#             for batch in range(n_batches):\n",
    "#                 X_train, y_train = loader.get_batch(batch)\n",
    "\n",
    "#                 X_train_torch = torch.tensor(X_train.values, dtype=torch.float)\n",
    "#                 y_train_torch = torch.tensor(y_train.values, dtype=torch.float)\n",
    "\n",
    "#                 X = X_train_torch.to(device)\n",
    "#                 y = y_train_torch.to(device)\n",
    "\n",
    "#                 pred = model(X)\n",
    "#                 loss = loss_fn(pred, y)\n",
    "        \n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 optimizer.zero_grad()\n",
    "#                 loss_history.append(loss.item())\n",
    "\n",
    "#         X_test, y_test = loader.get_batch(-1)\n",
    "\n",
    "#         model.eval()\n",
    "#         X_test_torch = torch.tensor(X_test.values, dtype=torch.float)\n",
    "#         y_test_torch = torch.tensor(y_test.values, dtype=torch.float)\n",
    "\n",
    "#         X = X_test_torch.to(device)\n",
    "#         y = y_test_torch.to(device)\n",
    "#         pred = model(X)\n",
    "\n",
    "        return X_train.values, y_train.values\n",
    "        return 0#loss.item()#.detatch()\n",
    "    \n",
    "    \n",
    "    \n",
    "    hp_tune = quante.carlo(instance, [[64, 128], [64, 128], [64, 128]], kernel=DotProduct()+ WhiteKernel(), \n",
    "                           n_batches=7, n_processors=4, n_iterations=5, keep_thread_id=True)\n",
    "    p = mp.Pool()\n",
    "    start = time.time()\n",
    "    \n",
    "#    session, iterations = hp_tune(p)\n",
    "    session = hp_tune(p)\n",
    "\n",
    "    print(\"{} seconds\".format(round(time.time() - start,2)))\n",
    "    results = p.map(instance, range(4))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "71d50151-40cc-4d54-9483-885b43e37f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 8.,  4.,  6., ...,  3.,  6.,  4.],\n",
       "        [ 4.,  2.,  3., ...,  3.,  7.,  6.],\n",
       "        [ 5.,  5.,  3., ...,  6.,  3.,  5.],\n",
       "        ...,\n",
       "        [ 1.,  5.,  3., ...,  9.,  9., 11.],\n",
       "        [ 3., 10.,  4., ...,  7.,  5.,  3.],\n",
       "        [ 7.,  2.,  4., ...,  4.,  3.,  4.]]),\n",
       " array([], shape=(0, 3750), dtype=object))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "de65d28e-4996-4274-b9b3-6b80575c0870",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m----> 2\u001b[0m X_train_torch \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "X_train_torch = torch.tensor(results[0][0], dtype=torch.float)\n",
    "X_train_torch = torch.tensor(results[0][1], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdc3608c-9b3c-48aa-97f7-b23905720377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_this = [tuple([i] +list(session.next_points[i])) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a1a7c33-60a0-4338-91b0-78d2c0a32ede",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(range(4), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48dec376-d2c8-4141-9dff-bc92f88a0cba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m n \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_layer_size, \u001b[43march\u001b[49m[\u001b[38;5;241m1\u001b[39m:], n_outputs\u001b[38;5;241m=\u001b[39moutput_layer_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arch' is not defined"
     ]
    }
   ],
   "source": [
    "n = NeuralNetwork(input_layer_size, , n_outputs=output_layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68d3e554-12da-4340-8d63-cc8bf33d2f85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.instance(p)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3704a-a948-49f4-9474-5a3a3747eac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
